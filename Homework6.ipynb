{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Course**: COMPSCI 589 Machine Learning, Fall 2024\n",
    "- **Instructor:** Justin Domke\n",
    "- **Assignment:** 6\n",
    "- **Group work policy:** You are allowed to complete this homework in teams of at most 3 students. However, each student must submit their own individual .pdf and .zip files to Gradescope, and submit your own solutions to [Kaggle](https://www.kaggle.com/t/b22337fb72164946a0502214ad599c73)[.](https://www.kaggle.com/t/f4b02988497040ef9ec91152b3057669) List your team members at the beginning of your `report.pdf`. You may verbally discuss the assignment with course staff or students outside your group, subject to conditions in the [Syllabus](https://www.notion.so/Syllabus-89f719731ae84d01b2e0b7b66088e48b?pvs=21). Please also list any students or course staff (separately) at the beginning of your `report.pdf`. However, you may not *look, copy, or show* any part of another student's assignment. Copying any part of another assignment — even a single sentence or line of code — from anyone outside your team is considered plagiarism. We use sophisticated tools to detect this. Please do not do it.\n",
    "- **AI usage policy**: Limited use is acceptable, subject to conditions in [Syllabus](https://www.notion.so/Syllabus-89f719731ae84d01b2e0b7b66088e48b?pvs=21).\n",
    "- **Due date:** Friday Nov 8th, 6:00 PM\n",
    "- **Submission instructions**:\n",
    "    - For this assignment, you can prepare your solutions in any manner you like. You may use Markdown, LaTeX, handwrite them, or a combination of these. Regardless of how they are prepared, you must produce a single .pdf file for your report, and a zip file containing your source files and your code that you upload to Gradescope.\n",
    "    - At the top of your .pdf file please include the following information:\n",
    "        - Your name\n",
    "        - Your email\n",
    "        - (Please do *not* include your student ID.)\n",
    "        - List anyone you discussed the assignment with, including course staff.\n",
    "    - Additionally, you **must submit a .zip file** in Gradescope. Your .zip file should contain three things:\n",
    "        - `report_src/` - A directory containing all source files for the report. This should include all files that you used to create your report .pdf (e.g. latex source files, plain text, images)\n",
    "        - `code/` - A directory containing Python code for all parts of the assignment.\n",
    "        - `code/run_me.py` - A single Python file that will generate all figures included in your report.\n",
    "    - [Gradescope](https://www.gradescope.com/) instructions: submit your **PDF** to [Gradescope](https://www.gradescope.com/courses/835228), click on **Assignment 6**, then click on **Submit PDF** to upload a single pdf file, submit your **ZIP** to Gradescope, click on **Assignment 6 - Code** to upload a single zip file. After the pdf has been uploaded, mark the correct pages for each question.  Contact [Ke](mailto:kexiao@cs.umass.edu) if you do not have access to the [Gradescope](https://www.gradescope.com/) page.\n",
    "    - For the purpose of late days, the **later** of your two submissions will be considered the submission time for your assignment. E.g., if you submit your .pdf on time, but the .zip is two days late, the assignment will be considered two days late.\n",
    "    - Finally, the assignment asks you to upload predictions to [Kaggle](https://www.kaggle.com/t/b22337fb72164946a0502214ad599c73).  *Please create a Kaggle account using your [umass.edu](http://umass.edu) email address*. Otherwise, it is very difficult for us to map Kaggle submissions to students.\n",
    "\n",
    "**Code:**\n",
    "\n",
    "- For this assignment you **may** use the methods in [`sklearn.tree`](https://scikit-learn.org/stable/api/sklearn.tree.html), [`sklinear.linear_model`](https://scikit-learn.org/stable/api/sklearn.linear_model.html), [`sklearn.metrics`](https://scikit-learn.org/stable/api/sklearn.metrics.html) and [`sklearn.neighbors`](https://scikit-learn.org/stable/api/sklearn.neighbors.html).\n",
    "- When using methods from [`sklinear.linear_model`](https://scikit-learn.org/stable/api/sklearn.linear_model.html), after training them you can call them via `decision_function()` only. Do **not** use `predict()` or `score()` or `predict_proba()`.\n",
    "- You may also use [`sklearn.model_selection.KFold`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html)  — but **not** any other methods in [`sklearn.model_selection`](https://scikit-learn.org/1.5/api/sklearn.model_selection.html).\n",
    "- If the assignment asks you to implement a particular function, you are expected to implement it yourself. If you find that the function is implemented somewhere within `sklearn` or `np` but not specifically banned above, your implementation should *not* consist of a call to that function. Example: If the question asked you to \"implement the cross entropy loss\", and you found that sklearn implemented \"cross_entropy_loss\" somewhere deep within the allowed packages, you should not just call the sklearn method, you should implement it yourself.\n",
    "\n",
    "**Note**: If you have any clarifying questions, you may use Notion’s “comment” functionality to highlight text and ask your question. (Please let Ke know if for any reason you are not able to make comments.) If you have deeper questions, please come to office hours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Preliminaries\n",
    "\n",
    "## Dataset\n",
    "\n",
    "In this assignment you are given a set of 29x29 RBG images. There are four possible labels. Your goal will be to train a predictor to recognize what is in the image. Here are a few elements of the training data, shown as images:You are given a file `data.npz`. \n",
    "\n",
    "[data.npz](https://prod-files-secure.s3.us-west-2.amazonaws.com/500c04b7-1a6e-4d1d-9794-74feb55ce8f4/469e893e-55b2-4237-8eb3-508550579599/data.npz)\n",
    "\n",
    "The data can be loaded as follows:\n",
    "\n",
    "```python\n",
    "stuff=np.load(\"data.npz\")\n",
    "X_trn = stuff[\"X_trn\"]\n",
    "y_trn = stuff[\"y_trn\"]\n",
    "X_tst = stuff[\"X_tst\"]\n",
    "# no Y_tst !\n",
    "```\n",
    "\n",
    "There are a total of 6000 training examples, and 1200 test examples, each with 2523 dimensions. Those dimensions correspond to 29x29x3 RBG images (29*29*3=2523). If you like, you can plot an example with the following code:\n",
    "\n",
    "```python\n",
    "from matplotlib import pyplot as plt\n",
    "def show(x):\n",
    "\t\timg = x.reshape((3,31,31)).transpose(1,2,0)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.draw()\n",
    "    plt.pause(0.01)\n",
    "show(X_trn[7])\n",
    "```\n",
    "\n",
    "## Kaggle\n",
    "\n",
    "Kaggle is a very popular platform for creating and running machine learning competitions. It allows the creators of competitions to evaluate submissions against a secret test set, ensuring that competitors cannot \"cheat\" by fine-tuning their model against the test set.\n",
    "\n",
    "The makers of Kaggle also created a set of features for creating an \"InClass\" competition, perfect for classes such as 589! We created a competition for this assignment in which you are required to participate. However, don't worry! It's not truly a \"competition\" as much as it is a way to automatically evaluate your submissions and to familiarize you with the Kaggle platform. Again, to make it easier for us to grade, *please create a Kaggle account using your @umass.edu email address*.\n",
    "\n",
    "The \"competition\" has two leaderboards: A public leaderboard and private leaderboard. The test set is split into two sets: A \"public\" set containing about 30% of the data and a \"private\" set containing the remaining 70%. In a normal competition, you can see how well your submission is performing against the public set. In theory, one could use brute force to find all of the correct answers. For this reason, in most competitions submissions are scored against the \"private\" set. This assignment will, at various points, ask you to report the performance of various solutions according to the public leaderboard.\n",
    "\n",
    "To submit solutions to Kaggle, you will be required to submit a `.csv` file with two columns: an \"Id\" column and a \"Category\" column classifying the integer prediction for each element in `X_tst`. A sample solution using randomly predicted outputs can be generated as follows:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "def write_csv(y_pred, filename):\n",
    "    \"\"\"Write a 1d numpy array to a Kaggle-compatible .csv file\"\"\"\n",
    "    with open(filename, 'w') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        csv_writer.writerow(['Id', 'Category'])\n",
    "        for idx, y in enumerate(y_pred):\n",
    "            csv_writer.writerow([idx, y])\n",
    "\n",
    "data = np.load('data.npz')\n",
    "X_tst = data['X_tst']\n",
    "y_pred = np.random.randint(0, 3, size=len(X_tst)) # random predictions\n",
    "write_csv(y_pred, 'sample_predictions.csv')\n",
    "```\n",
    "\n",
    "You can use the write_csv helper function in your code if you find it helpful to ensure that your solution is in the correct format.\n",
    "\n",
    "Note that the leaderboard shows *accuracy* whereas the assignment in some places asks for *classification error*. Note that these are related by\n",
    "\n",
    "$$\n",
    "\\text{Classification Error} = 1 - \\text{Accuracy},\n",
    "$$\n",
    "\n",
    "so it is easy to translate between the two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Part 1 - Classification\n",
    "\n",
    "**Question 1** (5 points) Take a very small dataset with five scalar inputs:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "x^{(1)} & = & 1.0 \\\\\n",
    "x^{(2)} & = & 2.0 \\\\\n",
    "x^{(3)} & = & 3.0 \\\\\n",
    "x^{(4)} & = & 4.0 \\\\\n",
    "x^{(5)} & = & 5.0 \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "There are two possible labels, as shown below:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "y^{(1)} & = & 1 \\\\\n",
    "y^{(2)} & = & 1 \\\\\n",
    "y^{(3)} & = & 0 \\\\\n",
    "y^{(4)} & = & 0 \\\\\n",
    "y^{(5)} & = & 1 \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "For each of the following split points, what is the information gain? Show your work.\n",
    "\n",
    "- Split at $x=0.5$\n",
    "- Split at $x=1.5$\n",
    "- Split at $x=2.5$\n",
    "- Split at $x=3.5$\n",
    "- Split at $x=4.5$\n",
    "- Split at $x=5.5$\n",
    "\n",
    "*Hint*: The information gain is defined to be the change in the entropy of the entropy that the split achieves. Let $I(p)=-\\sum_v \\hat{p}_v \\log \\hat{p}_v$ be the entropy of a distribution. We can calculate the distribution corresponding to any set of labels. For example, in the above dataset, $p=(0.4, 0.6).$ For a given split, the information gain is\n",
    "\n",
    "$$\n",
    "I(p)-\\frac{N_1 I(p_1) + N_2 I(p_2)}{N},\n",
    "$$\n",
    "\n",
    "where $p$ is the distribution of labels before splitting, $N$ is the total number of points,  $p_1$ and $p_2$ are the distributions of labels in the two datasets that result from splitting, and $N_1$ and $N_2$ are the number of points in the two datasets that result from splitting.\n",
    "\n",
    "*Hint 2:* Remember that when calculating entropies we interpret $0 \\log 0$ as being equal to $0$. (We do this because $\\lim_{x \\rightarrow 0+} x \\log x = 0$.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOLN\n",
    "Given that the information gain is given by $I(p)-\\frac{N_1 I (p_1) + N_2 I(p_2)}{N}$, where $$I(p)=-\\sum_{v}\\hat{p_v}$$\n",
    "\n",
    "We need to find the 'base entropy' without any splitting rules. This is $I(p)=-(0.4log_2(0.4)+0.6log_2(0.6))=0.9709$\n",
    "\n",
    "First, we use the splitting rule $x=0.5$, which gives us our initial section. No information gain.\n",
    "\n",
    "Next, we use $x=1.5$, which gives us two sections. The first corresponds to x1, and the second corresponds to x2,x3,x4,x5. $I(p_1)=-1 \\log_2 1=0$\n",
    "\n",
    "$I(p_2)=-(0.5log_2(0.5)+0.5log_2(0.5))=1$ The change in information then $0.9709-\\frac{4}{5}=0.1709$\n",
    "\n",
    "For $x=2.5$ we get the first two elements. $I(p_1)=-(1 log_2 1)=0$ and the second section is $I(p_2)=-(\\frac{1}{3} log_2(1/3) + \\frac{2}{3} log_2(2/3))=0.9182$\n",
    "\n",
    "This gives us an information gain of $0.9709 - \\frac{3\\cdot 0.9182}{5}=0.41998$\n",
    "\n",
    "For $x=3.5$ we get the first three elements. $I(p_1)=0.9182$ and $I(p_2)=1$\n",
    "\n",
    "Our information gain is $0.9709 - \\frac{0.9182 * 3 + 1 * 2}{5} = 0.01998$\n",
    "\n",
    "For $x=4.5$, $I(p_1)=1$ and $I(p_2)=0$ \n",
    "\n",
    "Our information gain is $0.9709 - \\frac{1*4}{5}=0.1709$ which is \n",
    "\n",
    "For $x=5.5$ our information gain is the same as for $x=0.5$ because no data is actually being split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "stuff=np.load(\"data.npz\")\n",
    "X_trn = stuff[\"X_trn\"]\n",
    "y_trn = stuff[\"y_trn\"]\n",
    "X_tst = stuff[\"X_tst\"]\n",
    "X_train_flattened = X_trn.reshape(len(X_trn), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Question 2** (8 points) Write your own class of classification stump `ClassificationStump`, with the following signature:\n",
    "\n",
    "```python\n",
    "class ClassificationStump():\n",
    "    def __init__(self):\n",
    "        return\n",
    "\n",
    "    def fit(self, X_trn, y_trn):\n",
    "        # do stuff here\n",
    "\n",
    "        self.model = (dim, thresh, c_left, c_right)\n",
    "        return\n",
    "\n",
    "    def predict(self, X_val, y_val):\n",
    "        assert hasattr(self, \"model\"), \"No fitted model!\"\n",
    "        # do stuff here (use self.model for prediction)\n",
    "\n",
    "        return y_pred\n",
    "```\n",
    "\n",
    "where `X_trn` is a 2D array of training inputs, and `y_trn` is a 1D array of training outputs. Your model `predict` function should predict the class to be `c_left` if `x[dim]<=thresh` and `c_right` otherwise, with `self.model` . Your model `fit` function should find values `dim`, `thresh`, `c_left`, and `c_right` to be used in the `predict` function such that the classification error is minimized:\n",
    "\n",
    "$$\n",
    "\\text{Classification Error} = \\frac{1}{N} \\sum_{i=1}^{N} \\mathbb{1}(y_i \\neq \\hat{y}_i)\n",
    "$$\n",
    "\n",
    "Where \n",
    "\n",
    "- N is the total number of training samples.\n",
    "- $y_i$ is the true class label.\n",
    "- $\\hat{y}_i$ is the predicted class label.\n",
    "- $\\mathbb{1}(y_i \\neq \\hat{y}_i)$ is the indicator function, evaluates to 1 if $y_i \\neq \\hat{y}_i$, and 0 otherwise.\n",
    "\n",
    "Train your `ClassificationStump` on the training data, and report the training classification error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ClassificationStump():\n",
    "    def __init__(self):\n",
    "        return\n",
    "\n",
    "    def fit(self, X_trn, y_trn):\n",
    "        # do stuff here\n",
    "        best_loss = np.inf\n",
    "\n",
    "        N, d = X_trn.shape\n",
    "        dim = d\n",
    "\n",
    "        for feature in range(d): # Extract features\n",
    "            sorted_idxs = np.argsort(X_trn[:, feature]) # The use of sorting helps find splits better\n",
    "            X_sorted = X_trn[sorted_idxs]\n",
    "\n",
    "            for idx in range(1, N): # loop over samples\n",
    "                # The threshold will be determined between two succesive points, reducing the amount of compute needed\n",
    "                curr_thresh = (X_sorted[idx - 1, feature] + X_sorted[idx, feature]) / 2\n",
    "                left_mask = X_trn[:, feature] <= curr_thresh\n",
    "                right_mask = X_trn[:, feature] > curr_thresh\n",
    "                \n",
    "                y_left = np.mean(y_trn[left_mask])\n",
    "                y_right = np.mean(y_trn[right_mask])\n",
    "\n",
    "                err_left = np.sum((y_trn[left_mask] - y_left) **2)\n",
    "                err_right = np.sum((y_trn[right_mask] - y_right) **2 )\n",
    "                err = err_left + err_right\n",
    "\n",
    "                if err < best_loss:\n",
    "                    dim = feature # Store the current dimension that we are splitting our data across\n",
    "                    best_loss = err_left + err_right \n",
    "                    thresh = curr_thresh # New splitting rule\n",
    "                    c_left = y_left\n",
    "                    c_right = y_right\n",
    "\n",
    "\n",
    "            self.model = (dim, thresh, c_left, c_right)\n",
    "            return\n",
    "\n",
    "    def predict(self, X_val, y_val):\n",
    "        assert hasattr(self, \"model\"), \"No fitted model!\"\n",
    "        # do stuff here (use self.model for prediction)\n",
    "        y_pred = []\n",
    "        dim = self.model[0]\n",
    "        thresh = self.model[1]\n",
    "        c_left = self.model[2]\n",
    "        c_right = self.model[3]\n",
    "        for idx, x in enumerate(X):\n",
    "            y_pred[idx] =  c_left if x[dim] <= thresh else c_right\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Question 3** (8 points) Train 6 different classification trees on the image data, with each of the following maximum depths: {1,3,6,9,12,14}. (Do not apply any other restriction when growing the tree, you may use `sklearn.tree` for this question). Use the trees to predict on the training data, and report the classification error as a 6x1 table. You should have one row for each max_depth and the corresponding training error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth=1, training error=0.6433\n",
      "max_depth=3, training error=0.5515\n",
      "max_depth=6, training error=0.4033\n",
      "max_depth=9, training error=0.2497\n",
      "max_depth=12, training error=0.1293\n",
      "max_depth=14, training error=0.0712\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "depths = [1,3,6,9,12,14]\n",
    "errors = [] \n",
    "\n",
    "# flatten 3D data to 2D\n",
    "# if X_trn shape is (num_samples, height, width, channels) or (num_samples, height, width)\n",
    "\n",
    "# train and calculate training error for each max_depth\n",
    "for depth in depths:\n",
    "    model = DecisionTreeClassifier(max_depth=depth)\n",
    "    model.fit(X_train_flattened, y_trn)\n",
    "    y_pred_train = model.predict(X_train_flattened)\n",
    "    \n",
    "    # calculate training error\n",
    "    trn_error = 1 - accuracy_score(y_trn, y_pred_train)\n",
    "    errors.append(trn_error)\n",
    "\n",
    "# display errors as 6x1 table\n",
    "for depth, error in zip(depths, errors):\n",
    "    print(f\"max_depth={depth}, training error={error:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Question 4** (5 points) Consider a classification tree with a maximum depth of $M$, trained on data width $D$ dimensions. What is the time complexity to evaluate that classification tree on a single new input? Give an answer (Something like \"order of $\\log(M) \\sqrt{D}$\") and explain in at most 3 sentences why your answer is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ans\n",
    "The time complexity is just O(M) since the number of dimensions does not relate to the number of computations that need to be done. That is purely defined by the depth of the tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5** (5 points) Take a dataset with $N$ elements each with $D$ dimensions. What is the time complexity to train a classification stump? Give an answer and explain why it's correct in at most 3 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ans\n",
    "A classification stump is a form of decision tree with depth M=1. Thus to train the stump over a dataset, we need to compare each point with all other points for all dimensions once. This gives us a complexity of $D(N(N-1))$ which is order $O(DN^2)$ in big O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Question 6** (10 points) Train a linear model with logistic loss, and ridge regularization, on the image data. That is, find w to minimize \n",
    "\n",
    "$$\n",
    "\\sum_{n=1}^N L(y^{(n)},W x^{(n)}) + \\lambda \\Vert W \\Vert^2.\n",
    "$$\n",
    "\n",
    "where L is the logistic loss.\n",
    "\n",
    "For this question, you need to train 5 different models with 5 different regularization constant $\\lambda \\in \\{10^{-1},1,10,100, 1000\\}$, and report the logistic loss and classification error on each one of the 5 models. Organize your numbers as a 5x2 table, with one row for each value of $\\lambda$ and one column for the logistic loss and the other column for the classification error. Again, you are allowed to use `sklearn.linear_model`. but you are not permitted to use `predict()` or  `predict_proba()` , but `decision_function()` is OK. \n",
    "\n",
    "**Note**: To avoid the convergence warning from showing up during training, set the following arguments: `max_iter=10000`, `tol=0.001`. This will increase the running time for your code, but it should finish within ~5 minutes. You can use lower `max_iter` for debugging purposes. \n",
    "\n",
    "**Hint**: The parameter `C` used in skelarn does not translate directly to `$\\lambda$` used in our objective function, choose `C` carefully so that it matches the  `$\\lambda$` we use. \n",
    "\n",
    "(**Hint**: Here $W$ is a matrix, so the ridge regularizer is $\\Vert W \\Vert^2 = \\sum_{v=1}^V \\sum_{i=1}^D W_{vd}^2$. This is technically known as the Frobenius norm. (But you shouldn’t need to implement this since `sklearn` does it for you if you use ridge regularization with multiclass linear predictors.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 1 ... 3 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=10.0, lambda=0.1, loss=0.4830, error=0.1733\n",
      "C=1.0, lambda=1.0, loss=0.5683, error=0.2063\n",
      "C=0.1, lambda=10.0, loss=0.6878, error=0.2627\n",
      "C=0.01, lambda=100.0, loss=0.7859, error=0.3025\n",
      "C=0.001, lambda=1000.0, loss=0.8779, error=0.3367\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# lambdas given in question\n",
    "lambdas = [0.1, 1, 10, 100, 1000]\n",
    "\n",
    "# C = 1/lambda in sklearn\n",
    "Cs = [1/lam for lam in lambdas]\n",
    "\n",
    "def softmax(z):\n",
    "    z = z - np.max(z, axis=1, keepdims=True)\n",
    "    exp_scores = np.exp(z)\n",
    "    return exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "\n",
    "def logistic_loss(scores, y_true):\n",
    "    pred = softmax(scores)\n",
    "    correct_class = pred[np.arange(len(y_true)), y_true]\n",
    "    return -np.mean(np.log(correct_class))\n",
    "\n",
    "results = []\n",
    "for C in Cs:\n",
    "    model = LogisticRegression(C=C, max_iter=1000, tol=0.001)\n",
    "    model.fit(X_train_flattened, y_trn)\n",
    "    \n",
    "    # Use decision_function() as specified\n",
    "    scores = model.decision_function(X_train_flattened)\n",
    "    loss = logistic_loss(scores, y_trn) \n",
    "    # For classification error:\n",
    "    pred_classes = np.argmax(scores, axis=1)\n",
    "    error = np.mean(pred_classes != y_trn)\n",
    "    \n",
    "    print(f\"C={C}, lambda={1/C}, loss={loss:.4f}, error={error:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Question 7** (8 points) Train a K nearest neighbor model for each of the following possible values of `K: {1,3,5,7,9,11}`. (Warning: This question might take a significant amount of computational time. You may consider using the `n_jobs` option.) Report the classification error as a 6x1 table, with one row for each value of K, and one column for the classification error. Note: you may use `sklearn.neighbors` for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num neighbors=1, training error=0.6433\n",
      "num neighbors=3, training error=0.5515\n",
      "num neighbors=5, training error=0.4033\n",
      "num neighbors=7, training error=0.2497\n",
      "num neighbors=9, training error=0.1293\n",
      "num neighbors=11, training error=0.0712\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "K = [1,3,5,7,9,11]      \n",
    "\n",
    "for k in K:\n",
    "    neigh = KNeighborsClassifier(n_neighbors=k)\n",
    "    neigh.fit(X_train_flattened, y_trn)\n",
    "    y_pred_train = neigh.predict(X_train_flattened)\n",
    "\n",
    "\n",
    "    # calculate training error\n",
    "    trn_error = 1 - accuracy_score(y_trn, y_pred_train)\n",
    "    errors.append(trn_error)\n",
    "\n",
    "# display errors as 6x1 table\n",
    "for k, error in zip(K, errors):\n",
    "    print(f\"num neighbors={k}, training error={error:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Question 8** (5 points) Consider a dataset with $N$ elements, each with $D$ dimensions. What is the time complexity to evaluate a K-nearest neighbors classifier? Give an answer and explain why it's correct in at most 3 sentences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three components. Firstly, we need to calculate the distances for all points which is $ND$, then we need to sort them which is complexity $NlogN$. Finally, we need to look at K points to decide what class our point is, this is $K$. In total, our complexity is $O(ND + NlogN + K)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Part 2 - Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Question 9** (8 points) In this question, you need to write your own K-Fold cross validation function `cross_validation()` with the following signature:\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def cross_validation(classifier, X_trn, y_trn, n_folds=5):\n",
    "    # do stuff here\n",
    "    \n",
    "    \n",
    "    # Return the paired (model and error) for all folds\n",
    "    return [(model1, error1), (model2, error2), ..., (modelK, errorK)]\n",
    "    \n",
    "\n",
    "# Usage for the cross_validation function:\n",
    "classifier = classifier_class(**args)\n",
    "outputs = cross_validation(classifier, \n",
    "                           X_trn, \n",
    "                           y_trn, \n",
    "                           n_folds=N)\n",
    "avg_error = np.mean([out_[1] for out_ in outputs])\n",
    "```\n",
    "\n",
    "Where you have `classifier` object to be trained, and `X_trn`, `y_trn` as input data, `n_folds` as the number of folds to split the data (`X_trn`, `y_trn`) for cross validation. The `classifier` object is expected to have functions `fit()` and  `predict()`. And the only sklearn function you are allowed to use in the cross_validation function is `sklearn.model_selection.KFold`, other imports are not allowed. The `classifier` are expected to have the following signature for `fit()` and `predict()` functions: \n",
    "\n",
    "```python\n",
    "class Classifier():\n",
    "    def __init__(self, **args):\n",
    "        ...\n",
    "        return\n",
    "\n",
    "    def fit(self, X_trn, y_trn):\n",
    "        ...\n",
    "        # self.model is stored\n",
    "        return\n",
    "\n",
    "    def predict(self, X_val, y_val):\n",
    "        ...\n",
    "        # self.model is used\n",
    "        return y_pred\n",
    "```\n",
    "\n",
    "In the `cross_validation` function, you should split the data into K folds ($\\text{fold}_1$, $\\text{fold}_2$, …, $\\text{fold}_K$), then train $K$ models where $\\text{model}_i$ is trained with {$\\text{fold}_1$, $\\text{fold}_2$, …, $\\text{fold}_{i-1}$, $\\text{fold}_{i+1}$, …, $\\text{fold}_{K}$} as the training data and {$\\text{fold}_i$} as the validation data to report the `out-of-sample` classification error on. Then return the trained K models and the corresponding out-of-sample `classification error`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## qs\n",
    "Write my own cross validation function which can use KFold\n",
    "\n",
    "Classifier is an object which can be trained and perform inference (e.g. it is a model)\n",
    "\n",
    "Not clear what methods can be used for the classifier... how to abstract this to an arbitrary model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def cross_validation(classifier, X_trn, y_trn, n_folds=5):\n",
    "    models = []\n",
    "    errors = []\n",
    "    kf = KFold(n_splits=n_folds)\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_trn):\n",
    "        # Train model on K-1 folds\n",
    "        classifier.fit(X_trn[train_index], y_trn[train_index])\n",
    "        \n",
    "        # Test on held-out fold\n",
    "        y_pred = classifier.predict(X_trn[test_index])\n",
    "\n",
    "        error = sum(y_pred != y_trn[test_index])/len(y_pred)\n",
    "        \n",
    "        models.append(classifier)\n",
    "        errors.append(error)\n",
    "    \n",
    "    return list(zip(models, errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Quesiton 10** (8 points) Train 6 different classification trees with `sklearn` modules on the image data, with each of the following maximum depths: `{1,3,6,9,12,14}`, like in `Q3`, but for this question, you should train it with 5-Fold cross-validation developed in `Q9`, estimate the mean on the out-of-sample (generalization) classification error, and report it as a 6x6 table. You should have one row for each `max_depth`, one column for each fold, and the last column for the mean over all 5 folds. (Do not apply any other restriction when growing the tree.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth  Fold1    Fold2    Fold3    Fold4    Fold5    Mean\n",
      "------------------------------------------------------------\n",
      "       1  0.6542  0.6617  0.6358  0.6375  0.6300  0.6438\n",
      "       3  0.5275  0.5692  0.5650  0.5475  0.5400  0.5498\n",
      "       6  0.4842  0.4933  0.4942  0.4833  0.4817  0.4873\n",
      "       9  0.4633  0.4925  0.4733  0.4667  0.4583  0.4708\n",
      "      12  0.4567  0.4850  0.4750  0.4642  0.4733  0.4708\n",
      "      14  0.4825  0.5025  0.4667  0.4667  0.4692  0.4775\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "\n",
    "depths = [1, 3, 6, 9, 12, 14]\n",
    "all_errors = []  # will store errors for each depth\n",
    "\n",
    "# Train and get cross-validation errors for each depth\n",
    "for depth in depths:\n",
    "    model = DecisionTreeClassifier(max_depth=depth)\n",
    "    outputs = cross_validation(model, X_train_flattened, y_trn, n_folds=5)\n",
    "    \n",
    "    # Get errors for all folds at this depth\n",
    "    fold_errors = [out[1] for out in outputs]\n",
    "    # Add mean error to create the 6th column\n",
    "    fold_errors.append(np.mean(fold_errors))\n",
    "    \n",
    "    all_errors.append(fold_errors)\n",
    "\n",
    "# Print 6x6 table\n",
    "print(\"max_depth  Fold1    Fold2    Fold3    Fold4    Fold5    Mean\")\n",
    "print(\"-\" * 60)\n",
    "for depth, errors in zip(depths, all_errors):\n",
    "    print(f\"{depth:8d}  {errors[0]:.4f}  {errors[1]:.4f}  {errors[2]:.4f}  {errors[3]:.4f}  {errors[4]:.4f}  {errors[5]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Question 11** (8 points) Train a linear model with logistic loss, and ridge regularization, on the image data, like in `Q6`. But for this question, you should train it with 5-fold cross-validation developed in `Q9`, estimate the mean on the out-of-sample (generalization) classification error, and report it as a 5x6 table. You should have one row for each of the 5 different regularization constant $\\lambda \\in \\{10^{-1},1,10,100, 1000\\}$, one column for each fold, and the last column for the mean over all 5 folds. You can use `sklearn` modules for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda    Fold1    Fold2    Fold3    Fold4    Fold5    Mean\n",
      "------------------------------------------------------------\n",
      "     0.1  0.4500  0.4717  0.4708  0.4508  0.4450  0.4577\n",
      "     1.0  0.4167  0.4342  0.4358  0.4308  0.4158  0.4267\n",
      "    10.0  0.3842  0.4017  0.3967  0.3975  0.3458  0.3852\n",
      "   100.0  0.3392  0.3800  0.3450  0.3617  0.3283  0.3508\n",
      "  1000.0  0.3458  0.3700  0.3525  0.3558  0.3325  0.3513\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "# lambdas given in question\n",
    "lambdas = [0.1, 1, 10, 100, 1000]\n",
    "# C = 1/lambda in sklearn\n",
    "Cs = [1/lam for lam in lambdas]\n",
    "all_errors = []\n",
    "\n",
    "# For each regularization strength\n",
    "for C in Cs:\n",
    "    model = LogisticRegression(C=C, max_iter=1000, tol=0.001)\n",
    "    outputs = cross_validation(model, X_train_flattened, y_trn, n_folds=5)\n",
    "    \n",
    "    # Get errors for all folds at this C value\n",
    "    fold_errors = [out[1] for out in outputs]\n",
    "    # Add mean error to create the 6th column\n",
    "    fold_errors.append(np.mean(fold_errors))\n",
    "    \n",
    "    all_errors.append(fold_errors)\n",
    "\n",
    "# Print 5x6 table\n",
    "print(\"lambda    Fold1    Fold2    Fold3    Fold4    Fold5    Mean\")\n",
    "print(\"-\" * 60)\n",
    "for lam, errors in zip(lambdas, all_errors):\n",
    "    print(f\"{lam:8.1f}  {errors[0]:.4f}  {errors[1]:.4f}  {errors[2]:.4f}  {errors[3]:.4f}  {errors[4]:.4f}  {errors[5]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Question 12** (8 points) ****Write ****your own K nearest neighbor classifier class, with the following signature: \n",
    "\n",
    "```python\n",
    "class KNNClassifier():\n",
    "    def __init__(self, n_neighbors):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        return\n",
    "\n",
    "    def fit(self, X_trn, y_trn):\n",
    "        # Just store X_trn, y_trn\n",
    "        self.model = (X_trn, y_trn)\n",
    "\n",
    "    def predict(self, X_val, y_val):\n",
    "        assert hasattr(self, \"model\"), \"No fitted model!\"\n",
    "        # do stuff here (use self.model for prediction)\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "knn = KNNClassifier(n_neighbors)\n",
    "models = cross_validation(knn, X_trn, y_trn, n_splits=5)\n",
    "# report on the models for each n_neighbors\n",
    "```\n",
    "\n",
    "where `X_trn` is a 2D array of training inputs, and `y_trn` is a 1D array of training outputs. Your `KNNClassifier.fit()` function just stores the training data which will be used in `KNNClassifier.predict()` function by accessing `self.model`. \n",
    "\n",
    "Then train a K nearest neighbor model (with your `KNNClassifier`) for each of the following possible values of K: `{1,3,5,7,9,11}`, like in `Q7`. But for this question, you should train it with 5-fold cross-validation developed in `Q9`, estimate the mean on the out-of-sample (generalization) classification error, and report it as a 6x6 table. You should have one row for each of the 6 `n_neighbors (K)`, one column for each fold, and the last column for the mean over all 5 folds. \n",
    "\n",
    "Hint: You should check the `classification error` against your own answers in `Q7` before using it for cross-validation training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNClassifier():\n",
    "    def __init__(self, n_neighbors):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        \n",
    "    def fit(self, X_trn, y_trn):\n",
    "        self.X_trn = X_trn\n",
    "        self.y_trn = y_trn\n",
    "        \n",
    "    def predict(self, X_val):\n",
    "        assert hasattr(self, \"X_trn\"), \"No fitted model!\"\n",
    "        \n",
    "        # Vectorized distance computation for all points at once\n",
    "        # Expand (a-b)^2 = a^2 + b^2 - 2ab\n",
    "        a2 = np.sum(X_val**2, axis=1, keepdims=True)\n",
    "        b2 = np.sum(self.X_trn**2, axis=1)\n",
    "        ab = X_val @ self.X_trn.T\n",
    "        \n",
    "        distances = np.sqrt(a2 + b2 - 2*ab)\n",
    "        \n",
    "        # Get k nearest neighbors for all points at once\n",
    "        k_indices = np.argsort(distances, axis=1)[:, :self.n_neighbors]\n",
    "        \n",
    "        # Get predictions for all points\n",
    "        k_nearest_labels = self.y_trn[k_indices]\n",
    "        y_pred = np.array([np.bincount(labels).argmax() \n",
    "                          for labels in k_nearest_labels])\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K    Fold1    Fold2    Fold3    Fold4    Fold5    Mean\n",
      "------------------------------------------------------------\n",
      "     1.0  0.4700  0.4583  0.4575  0.4408  0.4575  0.4568\n",
      "     3.0  0.4825  0.4583  0.4658  0.4542  0.4867  0.4695\n",
      "     5.0  0.4550  0.4417  0.4517  0.4325  0.4650  0.4492\n",
      "     7.0  0.4383  0.4292  0.4467  0.4267  0.4483  0.4378\n",
      "     9.0  0.4333  0.4258  0.4333  0.4333  0.4450  0.4342\n",
      "    11.0  0.4308  0.4350  0.4408  0.4275  0.4308  0.4330\n"
     ]
    }
   ],
   "source": [
    "# Run cross-validation\n",
    "K = [1, 3, 5, 7, 9, 11]\n",
    "all_errors = []\n",
    "\n",
    "for k in K:\n",
    "    model = KNNClassifier(n_neighbors=k)\n",
    "    outputs = cross_validation(model, X_train_flattened, y_trn, n_folds=5)\n",
    "    \n",
    "    # Get errors for all folds at this k value\n",
    "    fold_errors = [out[1] for out in outputs]\n",
    "    # Add mean error to create the 6th column\n",
    "    fold_errors.append(np.mean(fold_errors))\n",
    "    \n",
    "    all_errors.append(fold_errors)\n",
    "\n",
    "# Print 6x6 table\n",
    "print(\"K    Fold1    Fold2    Fold3    Fold4    Fold5    Mean\")\n",
    "print(\"-\" * 60)\n",
    "for k, errors in zip(K, all_errors):\n",
    "    print(f\"{k:8.1f}  {errors[0]:.4f}  {errors[1]:.4f}  {errors[2]:.4f}  {errors[3]:.4f}  {errors[4]:.4f}  {errors[5]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Question 13** (8 points) Choose the model from `Q10`, `Q11`, and`Q12` that you think will perform best on the public leaderboard (So 3 models in total). Make predictions for the test data and upload your predictions to [Kaggle](https://www.kaggle.com/t/b22337fb72164946a0502214ad599c73). Report:\n",
    "\n",
    "1. What classification model you chose\n",
    "2. What hyper-parameters you chose (e.g. K, $\\lambda$, etc.)\n",
    "3. What was your estimated generalization error using 5-fold cross validation.\n",
    "4. What accuracy you observed on the public part of the leaderboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Logistic Regression\n",
    "2. Lambda=100\n",
    "3. 35.08%\n",
    "4. 0.6492"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def softmax(z):\n",
    "    z = z - np.max(z, axis=1, keepdims=True)\n",
    "    exp_scores = np.exp(z)\n",
    "    return exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "\n",
    "def get_classes(scores, y_true):\n",
    "    pred = softmax(scores)\n",
    "    correct_class = pred[np.arange(len(y_true)), y_true]\n",
    "    return np.array(correct_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "stuff=np.load(\"data.npz\")\n",
    "X_trn = stuff[\"X_trn\"]\n",
    "y_trn = stuff[\"y_trn\"]\n",
    "X_tst = stuff[\"X_tst\"]\n",
    "X_test_flattened = X_tst.reshape(len(X_tst), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# lambdas given in question\n",
    "lam = 100\n",
    "\n",
    "# C = 1/lambda in sklearn\n",
    "C = 1/lam\n",
    "\n",
    "\n",
    "results = []\n",
    "model = LogisticRegression(C=C, max_iter=1000, tol=0.001)\n",
    "model.fit(X_train_flattened, y_trn)\n",
    "\n",
    "# Use decision_function() as specified\n",
    "scores = model.decision_function(X_train_flattened)\n",
    "classes = get_classes(scores, y_trn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "def write_csv(y_pred, filename):\n",
    "    \"\"\"Write a 1d numpy array to a Kaggle-compatible .csv file\"\"\"\n",
    "    with open(filename, 'w') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        csv_writer.writerow(['Id', 'Category'])\n",
    "        for idx, y in enumerate(y_pred):\n",
    "            csv_writer.writerow([idx, y])\n",
    "\n",
    "data = np.load('data.npz')\n",
    "X_tst = data['X_tst']\n",
    "y_pred = np.random.randint(0, 3, size=len(X_tst)) # random predictions\n",
    "write_csv(y_pred, 'sample_predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Question 14** (8 points). Like described in the assignment statement, the test set is split into **30% for the public leaderboard** and **70% for the private leaderboard**. You can see your model performance on the 30% public test set, while we will score your model performance on the 70% private leaderboard (which you have no access to) in this question. You can have **maximum 8 points** for your model performance on the **private leaderboard**. (No need to mark this question when submitting to Gradescope.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
